{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4c1e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.filters import gabor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ca6bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Function for lesion segmentation\n",
    "def segment_lesion(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding to segment the lesion\n",
    "    _, segmented_lesion = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Perform morphological operations to clean up the segmented region\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    segmented_lesion = cv2.morphologyEx(segmented_lesion, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Bitwise AND with the original image to obtain the segmented lesion\n",
    "    segmented_lesion = cv2.bitwise_and(image, image, mask=segmented_lesion)\n",
    "    \n",
    "    return segmented_lesion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "649e87a3-9105-472f-844c-2893d3e6f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract features from segmented lesions\n",
    "def extract_features(lesion_image):\n",
    "    # Calculate GLCM features\n",
    "    gray_image = cv2.cvtColor(lesion_image, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = graycomatrix(gray_image, distances=[5], angles=[0], symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, prop='contrast')[0, 0]\n",
    "    correlation = graycoprops(glcm, prop='correlation')[0, 0]\n",
    "    energy = graycoprops(glcm, prop='energy')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, prop='homogeneity')[0, 0]\n",
    "    \n",
    "    # Calculate Gabor features\n",
    "    frequency = 0.6\n",
    "    theta = 1.5\n",
    "    gabor_features, _ = gabor(gray_image, frequency=frequency, theta=theta)\n",
    "    mean_squared_energy = np.mean(gabor_features ** 2)\n",
    "    mean_amplitude = np.mean(np.abs(gabor_features))\n",
    "    \n",
    "    # Combine all features into a feature vector\n",
    "    feature_vector = [contrast, correlation, energy, homogeneity,mean_squared_energy, mean_amplitude]\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d4ee2542-caba-4a8e-b39e-d9fb97206efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 2520\n"
     ]
    }
   ],
   "source": [
    "def load_and_augment_images(directory):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    preprocessed_images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        aug_iter = datagen.flow(img)\n",
    "        \n",
    "        # Generate augmented images\n",
    "        num_augmented_images = 10  # Number of augmented images per original image\n",
    "        for _ in range(num_augmented_images):\n",
    "            augmented_image = aug_iter.next()[0].astype(np.uint8)\n",
    "            segmented_lesion = segment_lesion(augmented_image)\n",
    "            feature_vector = extract_features(segmented_lesion)\n",
    "            preprocessed_images.append(feature_vector)\n",
    "            labels.append(1 if 'oral_cancer' in filename else 0)\n",
    "    \n",
    "    print(f\"Number of images loaded: {len(preprocessed_images)}\")\n",
    "    return np.array(preprocessed_images), np.array(labels)\n",
    "\n",
    "images_directory = 'E:\\ocd\\Images'\n",
    "preprocessed_images, labels = load_and_augment_images(images_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "560c4f66-f3c7-4b7e-9023-1684d0827108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_images, labels, test_size=0.25, random_state=42)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce5051f0-bb96-4812-ad3c-efa45789e445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6206349206349207\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "nb_accuracy = nb_classifier.score(X_test, y_test)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f482c535-5b13-42f6-8837-6c937608ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.5761904761904761\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "knn_accuracy = knn_classifier.score(X_test, y_test)\n",
    "print(\"KNN Accuracy:\", knn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "546ac74d-705d-4258-9fd4-5c38c6c4a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6158730158730159\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_accuracy = svm_classifier.score(X_test, y_test)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
